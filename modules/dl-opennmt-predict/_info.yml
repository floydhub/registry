name: OpenNMT Predict using Seq2Seq Model
description: >
    Generate responses using Seq2Seq model trained using OpenNMT library's translate.lua (https://github.com/OpenNMT/OpenNMT/blob/master/translate.lua)
id: rS4vkHco5cTabC5Sc6A003
predecessor: rS4vkHco5cTabC5Sc6A002
version: 0.23
family_id: rS4vkHco5cTabC5Sc6AgRg
owner: support@floydhub.com
command: th /opennmt/translate.lua -src {{src}} -model {{model}} -output {{output}} -beam_size {{beam_size}} -n_best {{n_best}} -fallback_to_cpu {{fallback_to_cpu}} -gpuid {{gpuid}}
params:
    - name: beam_size
      type: int
      default: 5
      description: Beam size for search
    - name: n_best
      type: int
      default: 1
      description: If > 1, it will also output an n_best list of decoded sentences
    - name: fallback_to_cpu
      type: bool
      default: True
      description: If True, fallback to CPU if no GPU available
    - name: gpuid
      type: int
      default: -1
      description: 1-based identifier of the GPU to use. CPU is used when the option is < 1
inputs:
    - name: model
      type: file
      description: Trained Seq2Seq model
    - name: src
      type: text
      description: Source sequence to decode (one line per sentence)
outputs:
    - name: output
      type: text
      description: Path to output the predictions (each line will be the decoded sequence
default_container: docker:floydhub/opennmt:latest
language: Lua
tags: [dl, text, prediction, seq2seq, torch]
